{"cells":[{"cell_type":"markdown","metadata":{"id":"maVTL5fR52-g"},"source":["* Upload files to GDrive\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxSzIcYd5ymz"},"outputs":[],"source":["# from google.colab import files\n","# uploaded = files.upload()\n","# for fn in uploaded.keys():\n","#   print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"]},{"cell_type":"markdown","metadata":{"id":"DKyd142Myc0u"},"source":["*   To handle files from Google Drive, Colab should have the necessary permissions to mount the drive."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7DY7DHYvync"},"outputs":[],"source":["# import pandas as pd\n","# # Give permissions to colab handling files from gdrive\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","# # Check if the file exists\n","# import os\n","# file_path = '/content/gdrive/My Drive/SentimentBERT/dataset-test.csv'\n","# if os.path.exists(file_path):\n","#     print(\"File exists.\")\n","# else:\n","#     print(\"File does not exist.\")"]},{"cell_type":"markdown","metadata":{"id":"IEzDQ1lUy_uj"},"source":["* Use the training dataset uploaded to Google Drive to **train** the **BERT** model using **AdamW Optimizer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dk4ioPNpgY9j","colab":{"base_uri":"https://localhost:8080/","height":551,"referenced_widgets":["a1e5546f8f4344ac99f09652c5a23386","8a5732a027cf4c67a9657167f730cd5b","5f4b412f152946ea8b68b4e31bccb71c","92f6dc234ab24389ae0962eae00af8ff","1f2a36fec39a44c5ac68339951d8a1ea","76b308b2c6d541f491f52d5cf7947820","cffd39982f4348de9dbf82cc261eb2a2","40b86051ac4e47b1a686848a9a82c23b","cdcfe198f9ce4054a42aca21cbcbe4b1","ada3526954ce4b019247c230f42699be","cbd8be6a464c450483f642146a2c2994","0de93cb510234db4b963a3d096e45933","b89a2f8e8a604a34a9ce0864e11791d0","ada0d080e32141f6b35fcb39d6bab108","2d8dcdff94d04b8fa5aba43aafacf384","9e08686485bc4326813169b64e28efdb","e14c49d0b97347809880ddfc7958d63f","b9734d55fffd47c4a7056e1f451bed01","db3f412454ed435eb5039808170a550e","ecfb3a5abe05405182c962f2f5e44951","265aa03a2e394d4db11ef08d0376aa77","6705e4f6b322459184e0ca0a7f6de60e","a1972069a7454ede95cd6419658d87a8","328dbdb874974f56ac857d6cbaa2a9be","cb6f827c426342cdb3debc177883c71d","279cc65adfec4c6091a2c8b6e5d636e7","d926bab4aa5d45bcb5a09e90c7ef3f61","514d75470ee544b7a4ee4635b9578393","82928de6a95f457980c94857a934dc83","0e8704bef55b42f693b7400cf7f13ca3","2f2c566789bb4ce5ada94e738bc66fa2","a5a6367ca1904c93ab0a3a7dcfe585b2","993c29602f154b8db6657f3c3fc01670","2318997bc1514e1d88db9f4329bb2ac1","99c5c87afb714308bc2af19a86940f66","c72abed0f587480ea4240b7dec232e0c","a7864454d145419caf41f91033a27442","7e0819232e8d4d7299b615f615810b9f","dfa7276ece8045928ed656ae7e0e6a7f","0f8a15d502ad41df94e2f155f388883f","63689b2a99c44c88b7474acf12899c6b","3f507833869d427cafddff048efeced9","84dd227f14e949d1a262276d1c39ff23","2be88ed8fd5b4d6ea5b022374a5fb66b","0facb484ee90459496c9ab55251afd7e","d56bd993ded743e4b39d276ecb6953b5","b9ecf2b424c1412abf35bd5149627a3c","5aa24cb220f84fdd94616c4137f78838","8822258626644a6b814c6176e96cf2ec","67b8a26796654c64bc91d3a1518d5c9b","7c2c0acea3554fe8990f8c76bbfa59cf","dffb5a4a739d407783f4870ee5008141","abaf428222f54c38a49f84ba58eb91cd","1bfbea9adc5149bfb84c092310de840f","51382f06e5d144dca625b14bbeabbd0f"]},"executionInfo":{"status":"ok","timestamp":1710274942144,"user_tz":-120,"elapsed":186152,"user":{"displayName":"Roumeliotis Konstadinos","userId":"17264923090131634662"}},"outputId":"0f944ce8-b82c-4abb-919b-9d2f3fefdc26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e5546f8f4344ac99f09652c5a23386"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0de93cb510234db4b963a3d096e45933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1972069a7454ede95cd6419658d87a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2318997bc1514e1d88db9f4329bb2ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0facb484ee90459496c9ab55251afd7e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3: 100%|██████████| 160/160 [00:38<00:00,  4.19it/s]\n","Validation - Epoch 1/3: 100%|██████████| 40/40 [00:03<00:00, 12.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3 - Training Loss: 2.1398 - Validation Loss: 1.9285 - Validation Accuracy: 0.2125\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 160/160 [00:37<00:00,  4.32it/s]\n","Validation - Epoch 2/3: 100%|██████████| 40/40 [00:03<00:00, 12.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3 - Training Loss: 1.8399 - Validation Loss: 1.7850 - Validation Accuracy: 0.2812\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 160/160 [00:37<00:00,  4.31it/s]\n","Validation - Epoch 3/3: 100%|██████████| 40/40 [00:03<00:00, 12.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3 - Training Loss: 1.6396 - Validation Loss: 1.7619 - Validation Accuracy: 0.2687\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/gdrive/My Drive/AirlineReviews2k/BERT/adamw/tokenizer_config.json',\n"," '/content/gdrive/My Drive/AirlineReviews2k/BERT/adamw/special_tokens_map.json',\n"," '/content/gdrive/My Drive/AirlineReviews2k/BERT/adamw/vocab.txt',\n"," '/content/gdrive/My Drive/AirlineReviews2k/BERT/adamw/added_tokens.json')"]},"metadata":{},"execution_count":1}],"source":["import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig # Hugging Face transformers library\n","from torch.utils.data import Dataset, DataLoader # PyTorch for handling datasets and loading batches\n","from tqdm import tqdm # Progress bars\n","import torch # PyTorch functionalities\n","from sklearn.metrics import accuracy_score # Scikit-learn for evaluating classification accuracy\n","from torch.optim import AdamW as AdamW_Torch # AdamW Optimizer\n","from google.colab import drive # Use Google classes\n","\n","drive.mount('/content/gdrive') # Mount Google Drive using Google Colab to access files stored in Google Drive\n","df = pd.read_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/train_set_2k.csv\") # Load the test dataset from GDrive\n","\n","# Tokenization\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Instantiate a BERT tokenizer from the Hugging Face transformers library\n","# Tokenize the text data using the BERT tokenizer\n","tokenized = tokenizer(list(df['Review']), # Convert the column of the DataFrame into a Python list\n","                      padding=True, # Equal length sequences\n","                      truncation=True, # Truncate long reviews to fit the maximum allowed sequence length\n","                      return_tensors='pt') # Tokenizer output in PyTorch format  (PyTorch tensor - multi-dimensional array)\n","\n","# Number of classes for sentiment classification are the number of unique labels in the 'Overall_Rating' column\n","num_labels = len(df['Overall_Rating'].unique())\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, inputs, labels):\n","        self.inputs = inputs\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.inputs['input_ids'])\n","\n","    def __getitem__(self, idx):\n","        return {'input_ids': self.inputs['input_ids'][idx],\n","                'attention_mask': self.inputs['attention_mask'][idx],\n","                'labels': torch.tensor(self.labels[idx] - 1)} # Adjust labels to start from 0\n","\n","def evaluate_model(model, dataloader, device): # Evaluate model's accuracy on a given dataloader\n","    model.eval()\n","    all_labels = []\n","    all_predictions = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            inputs = {key: value.to(device) for key, value in batch.items()}\n","            labels = inputs[\"labels\"]\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","\n","            _, predicted = torch.max(logits, 1)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predictions.extend(predicted.cpu().numpy())\n","\n","    accuracy = accuracy_score(all_labels, all_predictions)\n","    return accuracy\n","\n","# Training dataset\n","train_dataset = CustomDataset(tokenized, # the output of BERT tokenizer\n","                              list(df['Overall_Rating'])) # Instantiate CustomDataset class\n","train_dataloader = DataLoader(train_dataset, # The DataLoader will iterate over CustomDataset\n","                              batch_size=8, # Number of samples in each mini-batch for memory-efficiency\n","                              shuffle=True # Randomly shuffles the data at the beginning of each epoch, preventing model from learning the order of the data (useful for generalization)\n","                              ) # Create a PyTorch DataLoader for the entire dataset\n","\n","# Validation dataset\n","validation_df = pd.read_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/validation_set_2k.csv\") # Load the validation dataset\n","tokenized_validation = tokenizer(list(validation_df['Review']),\n","                                  padding=True,\n","                                  truncation=True,\n","                                  return_tensors='pt') # Tokenize the text data\n","\n","validation_dataset = CustomDataset(tokenized_validation, list(validation_df['Overall_Rating']))\n","validation_dataloader = DataLoader(validation_dataset, batch_size=8, shuffle=False)\n","\n","# Load pre-trained BERT model with the correct num_labels\n","config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n","\n","# Fine-tuning\n","optimizer = AdamW_Torch(model.parameters(), lr=2e-5) # AdamW optimizer from PyTorch with a learning rate of 2e-5\n","\n","num_epochs = 3\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if it is available\n","model.to(device)\n","\n","# Loop over Epochs and Perform training\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_losses = []\n","\n","    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'): # Batch Loop with Progress Bar\n","        inputs = {key: value.to(device) for key, value in batch.items()} # Move input data to the selected device\n","        outputs = model(**inputs)\n","        loss = outputs.loss # Loss value from the model's output\n","        train_losses.append(loss.item()) # Append loss values to a list\n","\n","        optimizer.zero_grad() # Clear the gradients of all optimized parameters\n","        loss.backward() # Compute gradients of the loss during backpropagation\n","        optimizer.step() # Update model's parameters based on the computed gradients using the chosen AdamW optimization algorithm\n","\n","    # Validation loop\n","    model.eval()\n","    validation_losses = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(validation_dataloader, desc=f'Validation - Epoch {epoch + 1}/{num_epochs}'):\n","            inputs = {key: value.to(device) for key, value in batch.items()}\n","            outputs = model(**inputs)\n","            validation_losses.append(outputs.loss.item())\n","\n","    # Assess the accuracy of the trained model on the validation set\n","    accuracy = evaluate_model(model, validation_dataloader, device)\n","\n","    print(f'Epoch {epoch + 1}/{num_epochs} - Training Loss: {sum(train_losses) / len(train_losses):.4f} - Validation Loss: {sum(validation_losses) / len(validation_losses):.4f} - Validation Accuracy: {accuracy:.4f}')\n","\n","# Save the fine-tuned model and tokenizer to a directory\n","model.save_pretrained('/content/gdrive/My Drive/AirlineReviews2k/BERT/adamw')\n","tokenizer.save_pretrained('/content/gdrive/My Drive/AirlineReviews2k/BERT/adamw')\n"]},{"cell_type":"markdown","metadata":{"id":"85WSnVAHzcgP"},"source":["* Use the trained **BERT** model (**AdamW Optimizer**) to **predict** ratings for the **test** dataset."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5UASLNi6vrgy","executionInfo":{"status":"ok","timestamp":1710319967773,"user_tz":-120,"elapsed":1156360,"user":{"displayName":"Roumeliotis Konstadinos","userId":"17264923090131634662"}},"outputId":"75951536-aa96-4daa-f89e-f2b2cfac3c5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 81/1200 [01:27<16:29,  1.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n"," 24%|██▎       | 282/1200 [04:34<12:58,  1.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n"," 31%|███       | 368/1200 [05:54<11:45,  1.18it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n"," 31%|███       | 370/1200 [05:56<13:41,  1.01it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n"," 33%|███▎      | 392/1200 [06:17<11:44,  1.15it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n"," 35%|███▌      | 422/1200 [06:44<11:04,  1.17it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n"," 42%|████▏     | 509/1200 [08:07<11:38,  1.01s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n"," 44%|████▍     | 528/1200 [08:25<09:56,  1.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n"," 77%|███████▋  | 923/1200 [14:30<04:02,  1.14it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n","100%|██████████| 1200/1200 [18:46<00:00,  1.06it/s]\n"]}],"source":["import pandas as pd\n","import os\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from tqdm import tqdm  # tqdm for the progress bar\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Load the test dataset from GDrive\n","test_df = pd.read_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set.csv\")\n","\n","# Backup the original file by renaming it\n","os.rename(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set.csv\", \"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set_original1.csv\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available\n","\n","def load_fine_tuned_bert_model(model_path):\n","    # Load the fine-tuned model and tokenizer\n","    model = BertForSequenceClassification.from_pretrained(model_path) # Load a pre-trained BERT model for sequence classification\n","    tokenizer = BertTokenizer.from_pretrained(model_path) # Load the tokenizer\n","\n","    model.to(device) # Move model to GPU\n","\n","    return model, tokenizer\n","\n","def predict_star_rating(model, tokenizer, new_text, max_seq_length=512):\n","  # Tokenize and encode the new text\n","    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(new_text)))\n","\n","    # Truncate or split the sequence if it exceeds the maximum allowed length\n","    if len(tokens) > max_seq_length - 2:\n","        tokens = tokens[:max_seq_length - 2]\n","\n","    input_ids = tokenizer.encode(tokens, return_tensors=\"pt\").to(device)  # Tokenize and encode the input text using the BERT tokenizer\n","\n","    # Make predictions\n","    with torch.no_grad():\n","        model.eval()  # Set the BERT model to evaluation mode\n","        logits = model(input_ids)[0]  # Pass the encoded input through the BERT model to obtain logits (raw predictions)\n","        predictions = torch.argmax(logits, dim=1).item()  # Get the predicted class by finding the index with the maximum value in the logits tensor\n","\n","    # Return the predicted star rating\n","    return predictions + 1  # Adding 1 because star ratings are 1-indexed not 0-indexed\n","\n","def process_review_and_predict_rating(review_content):\n","  model_path = '/content/gdrive/My Drive/AirlineReviews2k/BERT/adamw'\n","  model, tokenizer = load_fine_tuned_bert_model(model_path)\n","\n","  predicted_rating = predict_star_rating(model, tokenizer, review_content) # Load the fine-tuned BERT model and tokenizer\n","  return predicted_rating\n","\n","# Create a progress bar for the loop\n","tqdm.pandas()\n","\n","# Iterate through each row in the DataFrame\n","for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","    # review_id = row['review_id']\n","    review_content = row['Review']\n","\n","    # Process the review and predict the star rating\n","    predicted_rating = process_review_and_predict_rating(review_content)\n","\n","    # Update the 'bert_adamw_ft_prediction' column\n","    test_df.at[index, 'bert_adamw_ft_2k_prediction'] = predicted_rating\n","\n","# Save the updated DataFrame back to the CSV file\n","test_df.to_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"uPEiGdBmK-xs"},"source":["* Use the training dataset uploaded to Google Drive to **train** the **BERT** model using **Adam Optimizer**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142167,"status":"ok","timestamp":1710275113055,"user":{"displayName":"Roumeliotis Konstadinos","userId":"17264923090131634662"},"user_tz":-120},"id":"XGQ3ju_CK8Pc","outputId":"69d1d774-e8f5-4d4c-d0ed-9c6aa780aaa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch 1/3: 100%|██████████| 160/160 [00:36<00:00,  4.35it/s]\n","Validation - Epoch 1/3: 100%|██████████| 40/40 [00:03<00:00, 12.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3 - Training Loss: 2.1320 - Validation Loss: 1.9282 - Validation Accuracy: 0.1938\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 160/160 [00:36<00:00,  4.35it/s]\n","Validation - Epoch 2/3: 100%|██████████| 40/40 [00:03<00:00, 12.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/3 - Training Loss: 1.8300 - Validation Loss: 1.7413 - Validation Accuracy: 0.2781\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 160/160 [00:36<00:00,  4.34it/s]\n","Validation - Epoch 3/3: 100%|██████████| 40/40 [00:03<00:00, 12.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/3 - Training Loss: 1.6006 - Validation Loss: 1.7212 - Validation Accuracy: 0.2812\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/gdrive/My Drive/AirlineReviews2k/BERT/adam/tokenizer_config.json',\n"," '/content/gdrive/My Drive/AirlineReviews2k/BERT/adam/special_tokens_map.json',\n"," '/content/gdrive/My Drive/AirlineReviews2k/BERT/adam/vocab.txt',\n"," '/content/gdrive/My Drive/AirlineReviews2k/BERT/adam/added_tokens.json')"]},"metadata":{},"execution_count":2}],"source":["import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig # Hugging Face transformers library\n","from torch.utils.data import Dataset, DataLoader # PyTorch for handling datasets and loading batches\n","from tqdm import tqdm # Progress bars\n","import torch # PyTorch functionalities\n","from sklearn.metrics import accuracy_score # Scikit-learn for evaluating classification accuracy\n","from torch.optim import Adam as Adam_Torch # Adam Optimizer\n","from google.colab import drive # Use Google classes\n","\n","drive.mount('/content/gdrive') # Mount Google Drive using Google Colab to access files stored in Google Drive\n","df = pd.read_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/train_set_2k.csv\") # Load the test dataset from GDrive\n","\n","# Tokenization\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # Instantiate a BERT tokenizer from the Hugging Face transformers library\n","# Tokenize the text data using the BERT tokenizer\n","tokenized = tokenizer(list(df['Review']), # Convert the column of the DataFrame into a Python list\n","                      padding=True, # Equal length sequences\n","                      truncation=True, # Truncate long reviews to fit the maximum allowed sequence length\n","                      return_tensors='pt') # Tokenizer output in PyTorch format  (PyTorch tensor - multi-dimensional array)\n","\n","# Number of classes for sentiment classification are the number of unique labels in the 'Overall_Rating' column\n","num_labels = len(df['Overall_Rating'].unique())\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, inputs, labels):\n","        self.inputs = inputs\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.inputs['input_ids'])\n","\n","    def __getitem__(self, idx):\n","        return {'input_ids': self.inputs['input_ids'][idx],\n","                'attention_mask': self.inputs['attention_mask'][idx],\n","                'labels': torch.tensor(self.labels[idx] - 1)} # Adjust labels to start from 0\n","\n","def evaluate_model(model, dataloader, device): # Evaluate model's accuracy on a given dataloader\n","    model.eval()\n","    all_labels = []\n","    all_predictions = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            inputs = {key: value.to(device) for key, value in batch.items()}\n","            labels = inputs[\"labels\"]\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","\n","            _, predicted = torch.max(logits, 1)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predictions.extend(predicted.cpu().numpy())\n","\n","    accuracy = accuracy_score(all_labels, all_predictions)\n","    return accuracy\n","\n","# Training dataset\n","train_dataset = CustomDataset(tokenized, # the output of BERT tokenizer\n","                              list(df['Overall_Rating'])) # Instantiate CustomDataset class\n","train_dataloader = DataLoader(train_dataset, # The DataLoader will iterate over CustomDataset\n","                              batch_size=8, # Number of samples in each mini-batch for memory-efficiency\n","                              shuffle=True # Randomly shuffles the data at the beginning of each epoch, preventing model from learning the order of the data (useful for generalization)\n","                              ) # Create a PyTorch DataLoader for the entire dataset\n","\n","# Validation dataset\n","validation_df = pd.read_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/validation_set_2k.csv\") # Load the validation dataset\n","tokenized_validation = tokenizer(list(validation_df['Review']),\n","                                  padding=True,\n","                                  truncation=True,\n","                                  return_tensors='pt') # Tokenize the text data\n","\n","validation_dataset = CustomDataset(tokenized_validation, list(validation_df['Overall_Rating']))\n","validation_dataloader = DataLoader(validation_dataset, batch_size=8, shuffle=False)\n","\n","# Load pre-trained BERT model with the correct num_labels\n","config = BertConfig.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n","\n","# Fine-tuning\n","optimizer = Adam_Torch(model.parameters(), lr=2e-5) # Adam optimizer from PyTorch with a learning rate of 2e-5\n","\n","num_epochs = 3\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if it is available\n","model.to(device)\n","\n","# Loop over Epochs and Perform training\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_losses = []\n","\n","    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'): # Batch Loop with Progress Bar\n","        inputs = {key: value.to(device) for key, value in batch.items()} # Move input data to the selected device\n","        outputs = model(**inputs)\n","        loss = outputs.loss # Loss value from the model's output\n","        train_losses.append(loss.item()) # Append loss values to a list\n","\n","        optimizer.zero_grad() # Clear the gradients of all optimized parameters\n","        loss.backward() # Compute gradients of the loss during backpropagation\n","        optimizer.step() # Update model's parameters based on the computed gradients using the chosen Adam optimization algorithm\n","\n","    # Validation loop\n","    model.eval()\n","    validation_losses = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(validation_dataloader, desc=f'Validation - Epoch {epoch + 1}/{num_epochs}'):\n","            inputs = {key: value.to(device) for key, value in batch.items()}\n","            outputs = model(**inputs)\n","            validation_losses.append(outputs.loss.item())\n","\n","    # Assess the accuracy of the trained model on the validation set\n","    accuracy = evaluate_model(model, validation_dataloader, device)\n","\n","    print(f'Epoch {epoch + 1}/{num_epochs} - Training Loss: {sum(train_losses) / len(train_losses):.4f} - Validation Loss: {sum(validation_losses) / len(validation_losses):.4f} - Validation Accuracy: {accuracy:.4f}')\n","\n","# Save the fine-tuned model and tokenizer to a directory\n","model.save_pretrained('/content/gdrive/My Drive/AirlineReviews2k/BERT/adam')\n","tokenizer.save_pretrained('/content/gdrive/My Drive/AirlineReviews2k/BERT/adam')"]},{"cell_type":"markdown","metadata":{"id":"yneu3AAIRBA0"},"source":["* Use the trained **BERT** model (**Adam Optimizer**) to **predict** ratings for the **test** dataset."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1117757,"status":"ok","timestamp":1710321890514,"user":{"displayName":"Roumeliotis Konstadinos","userId":"17264923090131634662"},"user_tz":-120},"id":"guL7t0KERIm6","outputId":"b50b7607-9b82-46a8-cd11-eb56dc97bbf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 81/1200 [01:24<17:43,  1.05it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n"," 24%|██▎       | 282/1200 [04:30<13:36,  1.12it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n"," 31%|███       | 368/1200 [05:49<13:57,  1.01s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n"," 31%|███       | 370/1200 [05:52<14:18,  1.03s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n"," 33%|███▎      | 392/1200 [06:12<11:36,  1.16it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n"," 35%|███▌      | 422/1200 [06:39<11:43,  1.11it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n"," 42%|████▏     | 509/1200 [07:59<09:41,  1.19it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n"," 44%|████▍     | 528/1200 [08:17<11:11,  1.00it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n"," 77%|███████▋  | 923/1200 [14:21<04:37,  1.00s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n","100%|██████████| 1200/1200 [18:34<00:00,  1.08it/s]\n"]}],"source":["import pandas as pd\n","import os\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from tqdm import tqdm  # tqdm for the progress bar\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Load the test dataset from GDrive\n","test_df = pd.read_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set.csv\")\n","\n","# Backup the original file by renaming it\n","os.rename(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set.csv\", \"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set_original2.csv\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available\n","\n","def load_fine_tuned_bert_model(model_path):\n","    # Load the fine-tuned model and tokenizer\n","    model = BertForSequenceClassification.from_pretrained(model_path) # Load a pre-trained BERT model for sequence classification\n","    tokenizer = BertTokenizer.from_pretrained(model_path) # Load the tokenizer\n","\n","    model.to(device) # Move model to GPU\n","\n","    return model, tokenizer\n","\n","def predict_star_rating(model, tokenizer, new_text, max_seq_length=512):\n","  # Tokenize and encode the new text\n","    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(new_text)))\n","\n","    # Truncate or split the sequence if it exceeds the maximum allowed length\n","    if len(tokens) > max_seq_length - 2:\n","        tokens = tokens[:max_seq_length - 2]\n","\n","    input_ids = tokenizer.encode(tokens, return_tensors=\"pt\").to(device)  # Tokenize and encode the input text using the BERT tokenizer\n","\n","    # Make predictions\n","    with torch.no_grad():\n","        model.eval()  # Set the BERT model to evaluation mode\n","        logits = model(input_ids)[0]  # Pass the encoded input through the BERT model to obtain logits (raw predictions)\n","        predictions = torch.argmax(logits, dim=1).item()  # Get the predicted class by finding the index with the maximum value in the logits tensor\n","\n","    # Return the predicted star rating\n","    return predictions + 1  # Adding 1 because star ratings are 1-indexed not 0-indexed\n","\n","def process_review_and_predict_rating(review_content):\n","  model_path = '/content/gdrive/My Drive/AirlineReviews2k/BERT/adam'\n","  model, tokenizer = load_fine_tuned_bert_model(model_path)\n","\n","  predicted_rating = predict_star_rating(model, tokenizer, review_content) # Load the fine-tuned BERT model and tokenizer\n","  return predicted_rating\n","\n","# Create a progress bar for the loop\n","tqdm.pandas()\n","\n","# Iterate through each row in the DataFrame\n","for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n","    # review_id = row['review_id']\n","    review_content = row['Review']\n","\n","    # Process the review and predict the star rating\n","    predicted_rating = process_review_and_predict_rating(review_content)\n","\n","    # Update the 'bert_adam_ft_prediction' column\n","    test_df.at[index, 'bert_adam_ft_2k_prediction'] = predicted_rating\n","\n","# Save the updated DataFrame back to the CSV file\n","test_df.to_csv(\"/content/gdrive/My Drive/AirlineReviews2k/Datasets/test_set.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyP5RCKGf0DHAuho6F7g23LK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a1e5546f8f4344ac99f09652c5a23386":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a5732a027cf4c67a9657167f730cd5b","IPY_MODEL_5f4b412f152946ea8b68b4e31bccb71c","IPY_MODEL_92f6dc234ab24389ae0962eae00af8ff"],"layout":"IPY_MODEL_1f2a36fec39a44c5ac68339951d8a1ea"}},"8a5732a027cf4c67a9657167f730cd5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76b308b2c6d541f491f52d5cf7947820","placeholder":"​","style":"IPY_MODEL_cffd39982f4348de9dbf82cc261eb2a2","value":"tokenizer_config.json: 100%"}},"5f4b412f152946ea8b68b4e31bccb71c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40b86051ac4e47b1a686848a9a82c23b","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cdcfe198f9ce4054a42aca21cbcbe4b1","value":48}},"92f6dc234ab24389ae0962eae00af8ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ada3526954ce4b019247c230f42699be","placeholder":"​","style":"IPY_MODEL_cbd8be6a464c450483f642146a2c2994","value":" 48.0/48.0 [00:00&lt;00:00, 1.36kB/s]"}},"1f2a36fec39a44c5ac68339951d8a1ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76b308b2c6d541f491f52d5cf7947820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cffd39982f4348de9dbf82cc261eb2a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40b86051ac4e47b1a686848a9a82c23b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdcfe198f9ce4054a42aca21cbcbe4b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ada3526954ce4b019247c230f42699be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbd8be6a464c450483f642146a2c2994":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0de93cb510234db4b963a3d096e45933":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b89a2f8e8a604a34a9ce0864e11791d0","IPY_MODEL_ada0d080e32141f6b35fcb39d6bab108","IPY_MODEL_2d8dcdff94d04b8fa5aba43aafacf384"],"layout":"IPY_MODEL_9e08686485bc4326813169b64e28efdb"}},"b89a2f8e8a604a34a9ce0864e11791d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e14c49d0b97347809880ddfc7958d63f","placeholder":"​","style":"IPY_MODEL_b9734d55fffd47c4a7056e1f451bed01","value":"vocab.txt: 100%"}},"ada0d080e32141f6b35fcb39d6bab108":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_db3f412454ed435eb5039808170a550e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ecfb3a5abe05405182c962f2f5e44951","value":231508}},"2d8dcdff94d04b8fa5aba43aafacf384":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_265aa03a2e394d4db11ef08d0376aa77","placeholder":"​","style":"IPY_MODEL_6705e4f6b322459184e0ca0a7f6de60e","value":" 232k/232k [00:00&lt;00:00, 1.37MB/s]"}},"9e08686485bc4326813169b64e28efdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e14c49d0b97347809880ddfc7958d63f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9734d55fffd47c4a7056e1f451bed01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db3f412454ed435eb5039808170a550e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecfb3a5abe05405182c962f2f5e44951":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"265aa03a2e394d4db11ef08d0376aa77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6705e4f6b322459184e0ca0a7f6de60e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1972069a7454ede95cd6419658d87a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_328dbdb874974f56ac857d6cbaa2a9be","IPY_MODEL_cb6f827c426342cdb3debc177883c71d","IPY_MODEL_279cc65adfec4c6091a2c8b6e5d636e7"],"layout":"IPY_MODEL_d926bab4aa5d45bcb5a09e90c7ef3f61"}},"328dbdb874974f56ac857d6cbaa2a9be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_514d75470ee544b7a4ee4635b9578393","placeholder":"​","style":"IPY_MODEL_82928de6a95f457980c94857a934dc83","value":"tokenizer.json: 100%"}},"cb6f827c426342cdb3debc177883c71d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e8704bef55b42f693b7400cf7f13ca3","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f2c566789bb4ce5ada94e738bc66fa2","value":466062}},"279cc65adfec4c6091a2c8b6e5d636e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5a6367ca1904c93ab0a3a7dcfe585b2","placeholder":"​","style":"IPY_MODEL_993c29602f154b8db6657f3c3fc01670","value":" 466k/466k [00:00&lt;00:00, 1.87MB/s]"}},"d926bab4aa5d45bcb5a09e90c7ef3f61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"514d75470ee544b7a4ee4635b9578393":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82928de6a95f457980c94857a934dc83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e8704bef55b42f693b7400cf7f13ca3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f2c566789bb4ce5ada94e738bc66fa2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5a6367ca1904c93ab0a3a7dcfe585b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993c29602f154b8db6657f3c3fc01670":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2318997bc1514e1d88db9f4329bb2ac1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99c5c87afb714308bc2af19a86940f66","IPY_MODEL_c72abed0f587480ea4240b7dec232e0c","IPY_MODEL_a7864454d145419caf41f91033a27442"],"layout":"IPY_MODEL_7e0819232e8d4d7299b615f615810b9f"}},"99c5c87afb714308bc2af19a86940f66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfa7276ece8045928ed656ae7e0e6a7f","placeholder":"​","style":"IPY_MODEL_0f8a15d502ad41df94e2f155f388883f","value":"config.json: 100%"}},"c72abed0f587480ea4240b7dec232e0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63689b2a99c44c88b7474acf12899c6b","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3f507833869d427cafddff048efeced9","value":570}},"a7864454d145419caf41f91033a27442":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84dd227f14e949d1a262276d1c39ff23","placeholder":"​","style":"IPY_MODEL_2be88ed8fd5b4d6ea5b022374a5fb66b","value":" 570/570 [00:00&lt;00:00, 16.6kB/s]"}},"7e0819232e8d4d7299b615f615810b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfa7276ece8045928ed656ae7e0e6a7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f8a15d502ad41df94e2f155f388883f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63689b2a99c44c88b7474acf12899c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f507833869d427cafddff048efeced9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84dd227f14e949d1a262276d1c39ff23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2be88ed8fd5b4d6ea5b022374a5fb66b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0facb484ee90459496c9ab55251afd7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d56bd993ded743e4b39d276ecb6953b5","IPY_MODEL_b9ecf2b424c1412abf35bd5149627a3c","IPY_MODEL_5aa24cb220f84fdd94616c4137f78838"],"layout":"IPY_MODEL_8822258626644a6b814c6176e96cf2ec"}},"d56bd993ded743e4b39d276ecb6953b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b8a26796654c64bc91d3a1518d5c9b","placeholder":"​","style":"IPY_MODEL_7c2c0acea3554fe8990f8c76bbfa59cf","value":"model.safetensors: 100%"}},"b9ecf2b424c1412abf35bd5149627a3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dffb5a4a739d407783f4870ee5008141","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_abaf428222f54c38a49f84ba58eb91cd","value":440449768}},"5aa24cb220f84fdd94616c4137f78838":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bfbea9adc5149bfb84c092310de840f","placeholder":"​","style":"IPY_MODEL_51382f06e5d144dca625b14bbeabbd0f","value":" 440M/440M [00:03&lt;00:00, 144MB/s]"}},"8822258626644a6b814c6176e96cf2ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67b8a26796654c64bc91d3a1518d5c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c2c0acea3554fe8990f8c76bbfa59cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dffb5a4a739d407783f4870ee5008141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abaf428222f54c38a49f84ba58eb91cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bfbea9adc5149bfb84c092310de840f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51382f06e5d144dca625b14bbeabbd0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}